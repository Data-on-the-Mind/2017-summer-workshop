{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(m):\n",
    "    \"\"\"Generate m random data points from each of two diferent normal \n",
    "    distributions with unit variance, for a total of 2*m points.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    m : int\n",
    "        Number of points per class\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    x, y : numpy arrays\n",
    "        x is a float array with shape (m, 2)\n",
    "        y is a binary array with shape (m,)\n",
    "    \n",
    "    \"\"\"\n",
    "    sigma = np.eye(2)\n",
    "    mu = np.array([[0, 2], [0, 0]])\n",
    "    mvrandn = np.random.multivariate_normal\n",
    "    x = np.concatenate([mvrandn(mu[:, 0], sigma, m), mvrandn(mu[:, 1], sigma, m)], axis=0)\n",
    "    y = np.concatenate([np.zeros(m), np.ones(m)], axis=0)\n",
    "    idx = np.arange(2 * m)\n",
    "    np.random.shuffle(idx)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_limits(axis, x):\n",
    "    \"\"\"Set the axis limits, based on the min and max of the points.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    axis : matplotlib axis object\n",
    "    x : array with shape (m, 2)\n",
    "    \n",
    "    \"\"\"\n",
    "    axis.set_xlim(x[:, 0].min() - 0.5, x[:, 0].max() + 0.5)\n",
    "    axis.set_ylim(x[:, 1].min() - 0.5, x[:, 1].max() + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_plot(x, y, boundary, loops):\n",
    "    \"\"\"Initialize the plot with two subplots: one for the training\n",
    "    error, and one for the decision boundary. Returns a function\n",
    "    that can be called with new errors and boundary to update the\n",
    "    plot.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy array with shape (m, 2)\n",
    "        The input data points\n",
    "    y : numpy array with shape (m,)\n",
    "        The true labels of the data\n",
    "    boundary : numpy array with shape (2, 2)\n",
    "        Essentially, [[xmin, ymin], [xmax, ymax]]\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    update_plot : function\n",
    "        This function takes two arguments, the array of errors and\n",
    "        the boundary, and updates the error plot with the new errors\n",
    "        and the boundary on the data plot.\n",
    "    \n",
    "    \"\"\"\n",
    "    plt.close('all')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    \n",
    "    error_line, = ax1.plot([0], [0], 'k-')\n",
    "    ax1.set_xlim(0, (loops * y.size) - 1)\n",
    "    ax1.set_ylim(0, 15)\n",
    "    ax1.set_xlabel(\"Iteration\")\n",
    "    ax1.set_ylabel(\"Training error\")\n",
    "    \n",
    "    colors = np.empty((y.size, 3))\n",
    "    colors[y == 0] = [0, 0, 1]\n",
    "    colors[y == 1] = [1, 0, 0]\n",
    "    ax2.scatter(x[:, 0], x[:, 1], c=colors, s=25)\n",
    "    normal_line, = ax2.plot(boundary[0, 0], boundary[0, 1], 'k-', linewidth=1.5)\n",
    "\n",
    "    set_limits(ax2, x)\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    def update_plot(errors, boundary):\n",
    "        error_line.set_xdata(np.arange(errors.size))\n",
    "        error_line.set_ydata(errors)\n",
    "        normal_line.set_xdata(boundary[:, 0])\n",
    "        normal_line.set_ydata(boundary[:, 1])\n",
    "        set_limits(ax2, x)\n",
    "        fig.canvas.draw()\n",
    "        \n",
    "    return update_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_normal(normal, weights):\n",
    "    \"\"\"Calculate the normal vector and decision boundary.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    normal : numpy array with shape (2,)\n",
    "        The normal vector to the decision boundary\n",
    "    weights : numpy array with shape (3,)\n",
    "        Weights of the perceptron\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    new_normal, boundary : numpy arrays\n",
    "        The new_normal array is the updated normal vector. The\n",
    "        boundary array is [[xmin, ymin], [xmax, ymax]] of the\n",
    "        boundary between the points.\n",
    "    \n",
    "    \"\"\"\n",
    "    new_normal = normal - (np.dot(weights[:2], normal) / np.dot(weights[:2], weights[:2])) * weights[:2]\n",
    "    new_normal = new_normal / np.dot(new_normal, new_normal)\n",
    "    offset = -weights[2] * weights[:2] / np.dot(weights[:2], weights[:2])\n",
    "    normmult = np.array([-1000, 1000])\n",
    "    boundary = (new_normal[None] * normmult[:, None]) + offset[None]\n",
    "    return new_normal, boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(m=20, alpha=0.5, loops=10):\n",
    "    \"\"\"Run a demo of training a perceptron.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    m : int\n",
    "        Number of datapoints per class\n",
    "    alpha : float\n",
    "        Initial learning rate\n",
    "    loops : int\n",
    "        Number of times to go through the data\n",
    "        \n",
    "    \"\"\"\n",
    "    # generate some random data\n",
    "    x, y = gen_data(m)\n",
    "        \n",
    "    # initialize helper variables\n",
    "    X = np.concatenate([x, np.ones((2 * m, 1))], axis=1)\n",
    "    errors = np.empty(loops * y.size)\n",
    "\n",
    "    # set up our initial weights and normal vectors\n",
    "    w = np.array([0, 0.2, 0])\n",
    "    normal, boundary = calc_normal(np.random.randn(2), w)\n",
    "\n",
    "    # initialize the plot\n",
    "    update_plot = init_plot(x, y, boundary, loops)\n",
    "\n",
    "    for i in range(loops):\n",
    "        # update the learning rate\n",
    "        alpha = alpha * 0.5\n",
    "\n",
    "        for j in range(y.size):\n",
    "            # number of iterations so far\n",
    "            k = i * y.size + j\n",
    "            \n",
    "            # compute the output of the perceptron and the error to the true labels\n",
    "            output = sigmoid(np.dot(w, X.T))\n",
    "            errors[k] = ((y - output) ** 2).sum()\n",
    "            \n",
    "            # update our weights and recalculate the normal vector\n",
    "            w += alpha * (y[j] - output[j]) * output[j] * (1 - output[j]) * X[j]\n",
    "            normal, boundary = calc_normal(normal, w)\n",
    "\n",
    "            # update the plot\n",
    "            update_plot(errors[:k], boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo(loops=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "estes",
   "language": "python",
   "name": "estes"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
