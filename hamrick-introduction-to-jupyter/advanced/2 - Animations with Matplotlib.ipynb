{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animations with Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the cool things about using `%matplotlib notebook` is that it allows us to actually create animations in the notebook! This is super useful for many reasons: visualizing how a model is training over time, creating animations for showing in talk, etc. In this part of the tutorial, we'll just look at an example of visualizing how a model is being trained. For examples of how to create standalone animations that you could show in a talk, see this blog post: https://jakevdp.github.io/blog/2012/08/18/matplotlib-animation-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nn import gen_data, Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we're going to train is a simple perceptron (no hidden units) that learns to classify 2D points into one of two classes. I have provided all the code to actually train the perceptron, so all we have to do is worry about plotting it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some random data\n",
    "x, y = gen_data(25)\n",
    "x[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of iterations to train for\n",
    "epochs = 250\n",
    "\n",
    "# create the perceptron, which will learn to classify the data\n",
    "perceptron = Perceptron(alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must construct the initial plot. We are going to create a plot with two subplots: one for plotting the training error, and one for plotting the points along with the classification boundary (which is provided to us via the `perceptron.boundary` variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "# construct the left plot, which will show our training error\n",
    "error_line, = ax1.plot([], [], 'k-')\n",
    "ax1.set_xlim(0, epochs)\n",
    "ax1.set_ylim(0, 15)\n",
    "ax1.set_xlabel(\"Iteration\")\n",
    "ax1.set_ylabel(\"Training error\")\n",
    "\n",
    "# construct the right plot, which will show the points and classification boundary\n",
    "colors = np.empty((y.size, 3))\n",
    "colors[y == 0] = [0, 0, 1]\n",
    "colors[y == 1] = [1, 0, 0]\n",
    "ax2.scatter(x[:, 0], x[:, 1], c=colors, s=25)\n",
    "normal_line, = ax2.plot(perceptron.boundary[:, 0], perceptron.boundary[:, 1], 'k-', linewidth=1.5)\n",
    "ax2.set_xlim(x[:, 0].min() - 0.5, x[:, 0].max() + 0.5)\n",
    "ax2.set_ylim(x[:, 1].min() - 0.5, x[:, 1].max() + 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the above code, we saved the output of `ax1.plot` and `ax2.plot` to variables called `error_line` and `normal_line` respectively. These are the plot objects that we will then update as we train the perceptron.\n",
    "\n",
    "To actually train the perceptron, we can construct a loop were we call `perceptron.train()` on each iteration. Then, we use the methods `.set_xdata()` and `.set_ydata()` on our line objects to update the values of the lines, and we finally call `fig.canvas.draw()` to get the whole thing to refresh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    # compute the output of the perceptron and the error to the true labels\n",
    "    errors.append(perceptron.train(x, y))\n",
    "\n",
    "    # update the training error curve\n",
    "    error_line.set_xdata(np.arange(len(errors)))\n",
    "    error_line.set_ydata(errors)\n",
    "    \n",
    "    # update the decision boundary\n",
    "    normal_line.set_xdata(perceptron.boundary[:, 0])\n",
    "    normal_line.set_ydata(perceptron.boundary[:, 1])\n",
    "    \n",
    "    # redraw the plot\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Try creating another animated plot, this time displaying the weights. These can be accessed via `perceptron.w` and `perceptron.b`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: if you use a bar plot (with `ax.bar`), you cannot set the data directly on the returned object. Instead, you must iterate through it and set the height of each bar individually (`bar.set_height()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate the perceptron\n",
    "perceptron = Perceptron(alpha=0.2)\n",
    "\n",
    "################################# \n",
    "# create your initial plot here #\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    perceptron.train(x, y)\n",
    "    \n",
    "    #########################\n",
    "    # update your plot here #\n",
    "    #########################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
