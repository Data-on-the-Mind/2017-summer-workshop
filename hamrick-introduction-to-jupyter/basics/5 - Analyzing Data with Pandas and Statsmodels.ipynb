{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Data with Pandas and Statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the tutorial, we will go through common ways to use Pandas and statsmodels to analyze data. The dataset we'll be analyzing comes from first experiment in the following paper:\n",
    "\n",
    "Hamrick, J. B., Smith, K. A., Griffiths, T. L., & Vul, E. (2015). Think again? The amount of mental simulation tracks uncertainty in the outcome. In Proceedings of the 37th Annual Conference of the Cognitive Science Society. Austin, TX.\n",
    "\n",
    "In this experiment, participants looked at a ball bouncing around in a box, and had to determine whether that ball would go through a hole in the wall or not:\n",
    "\n",
    "![](images/experiment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/ball.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stimuli in this dataset vary based on the number of times the ball bounces, the margin by which it does or does not go in the hole, and the size of the hole itself. There are 48 initial starting trajectories for the ball (reflected by the `\"stim\"` column), four different ways the ball can go in or miss the hole (reflected by the `\"hole_class\"` column), and two hole sizes (reflected by the `\"hole_width\"` column)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract different types of judgments using the `.query()` method of a DataFrame, for example to pull out judgments only for trials in which the ball went in the hole:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goesin = data.query(\"goes_in == True\")\n",
    "goesin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a DataFrame containing only the data on trials in which the ball went in the hole, we can easily visualize them using built-in Pandas plotting methods, such as `.hist()`. For example, to view the histogram of response times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goesin['rt'].hist(grid=False, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $x$-axis has a really high limit here, suggesting we have some very large outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goesin['rt'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed. We can also use query to pull out only those response times that are within a certain range, such as the 99% interval centered around the median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, hi = np.percentile(goesin[\"rt\"], [0.5, 99.5])\n",
    "data = data.query(\"rt > {} and rt < {}\".format(lo, hi))\n",
    "goesin = data.query(\"goes_in == True\")\n",
    "goesin['rt'].hist(grid=False, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Using the query method, query for stimuli where the ball missed the hole by a small margin *and* bounced once, and then visualize the response times using a histogram.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be nice to look at not just histograms, but also response averages and standard deviations. This is very easy to do with the `.groupby()` operation of the DataFrame. This is a complex operation and can at times be confusing to understand, so I recommend reading throught he Pandas documentation on this concept: https://pandas.pydata.org/pandas-docs/stable/groupby.html\n",
    "\n",
    "The basic idea is to split the DataFrame apart into separate DataFrames, apply some operation, and then recombine them. So, we can take this procedure to (for example), split the `fall` DataFrame apart into separate DataFrames for each stimulus, compute the average response, and then recombine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby stimulus, hole width, and hole class, and then compute the mean of the 'response' column for each group\n",
    "mean_resp = data.groupby([\"stim\", \"hole_width\", \"hole_class\"])[\"response\"].mean()\n",
    "mean_resp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the above operation, I've passed a list to the groupby operation---this tells it to group by unique values in *multiple* columns, so that we get one group for each stimulus and mass ratio.\n",
    "\n",
    "Pandas comes with some built-in methods that can be applied to groups, like `.mean()`. But what if you wanted to use a function that wasn't predefined? We can easily do this using `.apply()`, which takes as an argument the function to execute. The following is equivalent to using `.mean()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby([\"stim\", \"hole_width\", \"hole_class\"])[\"response\"].apply(np.mean).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can provide any function which returns either a scalar (e.g., `np.mean`) or a Pandas `Series` object. The Series object is like a column of a DataFrame: it has labeled rows, but is only a single column. For example, we could write a function that returns a variety of statistics as a Series object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_stats(group):\n",
    "    stats = pd.Series({\n",
    "        \"mean\": group.mean(),\n",
    "        \"median\": group.median(),\n",
    "        \"std\": group.std(),\n",
    "        \"sem\": scipy.stats.sem(group)\n",
    "    })\n",
    "    \n",
    "    # this is so the column in the resulting DataFrame,\n",
    "    # after using groupby, has a label\n",
    "    stats.index.name = \"statistic\"\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_stats = data.groupby([\"stim\", \"hole_width\", \"hole_class\"])[\"response\"].apply(calc_stats)\n",
    "resp_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Try grouping the `data` DataFrame by the number of bounces, the hole size, and the hole class, and then compute the mean **response time** of each of those groups.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Massaging DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming back to our `resp_stats` object, let's say we want to pull out just the mean statistic. If we try doing this with `.query()`, as we saw before, we find it fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_stats.query(\"statistic == 'mean'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What gives? The issue is that `resp_stats` isn't a DataFrame---it's a Series object, which means it doesn't have any columns that we can query! There are two options we can use to turn it into a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Between Columns and Indicies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first option is to use the `.to_frame()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_stats.to_frame(\"value\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is now a DataFrame, but it still doesn't have a column for `\"statistic\"` -- that's part of the index. To turn columns in the index to real columns in the DataFrame, we can use the `.reset_index()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_stats.to_frame(\"value\").reset_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can query for the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_stats.to_frame(\"value\").reset_index().query(\"statistic == 'mean'\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can make columns part of the index again by using the `.set_index()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_stats\\\n",
    "    .to_frame(\"value\")\\\n",
    "    .reset_index()\\\n",
    "    .query(\"statistic == 'mean'\")\\\n",
    "    .set_index([\"stim\", \"hole_width\", \"hole_class\"])\\\n",
    "    .head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we don't really need to use `.set_index()` here again; I am showing it for demonstration purposes only---though it certainly does come in handy sometimes! If we really wanted to to what we had just done, it would be better to pass just the `\"statistic\"` column to `.reset_index()` in the first place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_stats.to_frame(\"value\").reset_index(\"statistic\").query(\"statistic == 'mean'\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking, Unstacking, and Pivoting DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other option to isolate only the mean values is to \"unstack\" the `\"statistic\"` column. This converts it from a part of the index to a series of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_stats.unstack(\"statistic\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can easily query the mean column by just indexing into the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_stats.unstack(\"statistic\")[\"mean\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method also makes it easy to select multiple columns at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_stats.unstack(\"statistic\")[[\"mean\", \"std\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can convert it back to a Series object using the `.stack()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_stats.unstack(\"statistic\")[[\"mean\", \"std\"]].stack().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Statistics with Statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For basic statistic, the [statsmodels package](http://www.statsmodels.org/stable/index.html) is a great resource. It doesn't have quite the breadth of statistical functions available as are present in R, but for quick and easy linear modeling it can be quite useful.\n",
    "\n",
    "Let's take a look at whether people's response time varies as a function of the hole class and width. First, however, we'll compute log response times to work with, because response time is often very close to log-normally distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column in `mass` that reflects whether responses are equal to the true answer\n",
    "data[\"log_rt\"] = np.log(data[\"rt\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"log_rt\"].hist(grid=False, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the plot that the response times are almost, though not quite, normally distributed. A Q-Q plot will help us see this further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.gofplots import qqplot\n",
    "qqplot(data[\"log_rt\"], line='45');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we are ready to try building our first model. We'll create a binomial GLM predicting accuracy as a function of the true ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(\"log_rt ~ hole_class * hole_width\", data=data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute an ANOVA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.api import anova_lm\n",
    "anova_lm(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the results that both the hole size and the margin by which the ball does/does not go in the hole significantly affect response times, and that there is also an interaction between these variables.\n",
    "\n",
    "(Note: there is a major issue with this analysis, which is that it doesn't take into account the fact that we have multiple measures of each stimulus and multiple responses from each participant. A better analysis would be to use a mixed-effects model, but statsmodels unfortunately doesn't have good support for that.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Putting it all together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<ul>\n",
    "<li> Compute average log response times and responses for each stimulus, hole width, and hole class pair (averaging across participants).\n",
    "<li> Plot the relationship between average responses ($x$-axis) and average log response times ($y$-axis).\n",
    "<li> Use statsmodels to determine whether there is a relationship between average responses and average log response times. Is the relationship first order or second order?\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hint #1: you can create a DataFrame out of series objects like so: `df = pd.DataFrame({\"col_a\": a, \"col_b\": b})`\n",
    "* Hint #2: to include a second-order factor in your linear model, you can use `I` like so: `I(varname ** 2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
