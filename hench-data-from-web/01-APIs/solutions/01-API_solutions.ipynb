{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Databases via Web APIs\n",
    "* * * * *\n",
    "\n",
    "In this lesson we'll learn what an API (Application Programming Interface) is, how it's normally used, and how we can collect data from it. We'll then look at how Python can help us quickly gather data from APIs, parse the data, and write to a CSV. There are four sections:\n",
    "\n",
    "1. Constructing an API GET request\n",
    "2. Parsing the JSON response\n",
    "3. Looping through result pages\n",
    "4. Exporting to CSV\n",
    "\n",
    "First we'll import the required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests  # to make the GET request \n",
    "import json  # to parse the JSON response to a Python dictionary\n",
    "import time  # to pause after each API call\n",
    "import csv  # to write our data to a CSV\n",
    "import pandas  # to see our CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these are standard Python libraries, so no matter your distribution, these should be installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Constructing an API GET request\n",
    "*****\n",
    "\n",
    "We're going to use the New York Times API. You'll need to first [sign up for an API key](https://developer.nytimes.com/signup).\n",
    "\n",
    "We know that every call to any API will require us to provide:\n",
    "\n",
    "1. a base URL for the API, \n",
    "2. (usually) some authorization code or key, and \n",
    "3. a format for the response.\n",
    "\n",
    "Let's write this information to some variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set API key var\n",
    "key = \"\"\n",
    "\n",
    "# set base url var\n",
    "base_url = \"http://api.nytimes.com/svc/search/v2/articlesearch\"\n",
    "\n",
    "# set response format var\n",
    "response_format = \".json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we assign each variable as a string. While the `requests` library will convert integers, it's better to be consistent and use strings for all parameters of a GET request. We choose JSON as the response format, as it is easy to parse quickly with Python, though XML is often an viable frequently offered alternative. JSON stands for \"Javascript object notation.\" It has a very similar structure to a python dictionary -- both are built on key/value pairs.\n",
    "\n",
    "You often want to send some sort of data in the URL’s query string. This data tells the API what information you want. In our case, we're going to look for articles about Duke Ellington. Requests allows you to provide these arguments as a dictionary, using the `params` keyword argument. In addition to the search term `q`, we have to put in the `api-key` term. We know these key names from the [NYT API documentation](http://developer.nytimes.com/article_search_v2.json#/Documentation/GET/articlesearch.json)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set search parameters\n",
    "search_params = {\"q\": \"Duke Ellington\",\n",
    "                 \"api-key\": key}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to make the request. We use the `.get` method from the `requests` library to make an HTTP GET Request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make request\n",
    "response = requests.get(base_url + response_format, params=search_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a [response](http://docs.python-requests.org/en/latest/api/#requests.Response) object called `response`. We can get all the information we need from this object. For instance, we can see that the URL has been correctly encoded by printing the URL. Click on the link to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(response.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on that link to see it returns! Notice that all Python is doing here for us is helping us construct a complicated URL built with `&` and `=` signs. You just noticed we could just as well copy and paste this URL to a browser and then save the response, but Python's `requests` library is much easier and scalable when making multiple queries in succession."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1:  Adding a date range\n",
    "\n",
    "What if we only want to search within a particular date range? The NYT Article API allows us to specify start and end dates.\n",
    "\n",
    "Alter the `search_params` code above so that the request only searches for articles in the year 2015.\n",
    "\n",
    "You're going to need to look at the [documentation](http://developer.nytimes.com/docs/read/article_search_api_v2) to see how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set date parameters here\n",
    "\n",
    "search_params = {\"q\": \"Duke Ellington\",\n",
    "                 \"api-key\": key,\n",
    "                 \"begin_date\": \"20150101\",  # date must be in YYYYMMDD format\n",
    "                 \"end_date\": \"20151231\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# uncomment to test\n",
    "r = requests.get(base_url + response_format, params=search_params)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2:  Specifying a results page\n",
    "\n",
    "The above will return the first 10 results. To get the next ten, you need to add a \"page\" parameter. Change the search parameters above to get the second 10 results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set page parameters here\n",
    "\n",
    "search_params[\"page\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# uncomment to test\n",
    "r = requests.get(base_url + response_format, params=search_params)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parsing the JSON response\n",
    "*****\n",
    "\n",
    "We can read the content of the server’s response using `.text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inspect the content of the response, parsing the result as text\n",
    "response_text = r.text\n",
    "print(response_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you see here is JSON text, encoded as unicode text. As mentioned, JSON is bascially a Python dictionary, and we can convert this string text to a Python dictionary by using the `loads` to load from a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert JSON response to a dictionary\n",
    "data = json.loads(response_text)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks intimidating! But it's really just a big dictionary. The most time-consuming part of using APIs is traversing the various key-value trees to see where the information you want resides. Let's see what keys we got in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is boring\n",
    "print(data['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# so is this\n",
    "print(data['copyright'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is what we want!\n",
    "print(data['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data['response'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data['response']['meta'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data['response']['meta']['hits'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there were 93 hits total for our query. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data['response']['docs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It starts with a square bracket, so it looks like a `list`, and from a glance it looks like the list of articles we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(type(data['response']['docs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just save this list to a new variable. Often when using web APIs, you'll spend the majority of your time restructuring the response data to how you want it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs = data['response']['docs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! That's a lot of information about just one article! But wait..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Looping through result pages\n",
    "*****\n",
    "\n",
    "We're making progress, but we only have 10 items. The original response said we had 93 hits! Which means we have to make 93 /10, or 10 requests to get them all. Sounds like a job for a loop! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get number of hits total (in any page we request)\n",
    "hits = data['response']['meta']['hits']\n",
    "print(\"number of hits: \", str(hits))\n",
    "\n",
    "# get number of pages\n",
    "pages = hits // 10 + 1\n",
    "\n",
    "# make an empty list where we'll hold all of our docs for every page\n",
    "all_docs = []\n",
    "\n",
    "# now we're ready to loop through the pages\n",
    "for i in range(pages):\n",
    "\n",
    "    print(\"collecting page\", str(i))\n",
    "\n",
    "    # set the page parameter\n",
    "    search_params['page'] = i\n",
    "\n",
    "    # make request\n",
    "    r = requests.get(base_url + response_format, params=search_params)\n",
    "\n",
    "    # get text and convert to a dictionary\n",
    "    data = json.loads(r.text)\n",
    "\n",
    "    # get just the docs\n",
    "    docs = data['response']['docs']\n",
    "\n",
    "    # add those docs to the big list\n",
    "    all_docs = all_docs + docs\n",
    "\n",
    "    # IMPORTANT pause between calls\n",
    "    time.sleep(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(all_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exporting to CSV\n",
    "*****\n",
    "\n",
    "Great, now we have all the articles. Let's just take out some bits of information and write to a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_docs = []\n",
    "\n",
    "for d in all_docs:\n",
    "    \n",
    "    # create empty dict for each doc to collect info\n",
    "    targeted_info = {}\n",
    "    targeted_info['id'] = d['_id']\n",
    "    targeted_info['headline'] = d['headline']['main']\n",
    "    targeted_info['date'] = d['pub_date'][0:10]  # cutting time of day.\n",
    "    targeted_info['word_count'] = d['word_count']\n",
    "    targeted_info['keywords'] = [keyword['value'] for keyword in d['keywords']]\n",
    "    try:  # some docs don't have this info\n",
    "        targeted_info['lead_paragraph'] = d['lead_paragraph']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # append final doc info to list\n",
    "    final_docs.append(targeted_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write our sifted information to a CSV now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header = final_docs[1].keys()\n",
    "\n",
    "with open('all-docs.csv', 'w') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, header)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(final_docs)\n",
    "\n",
    "pandas.read_csv('all-docs.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
