{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reproducibility\n",
        "\n",
        "Adapted from Sandve, G. K., Nekrutenko, A., Taylor, J., & Hovig, E. (2013). Ten simple rules for reproducible computational research. PLoS Computational Biology, 9(10), e1003285.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computational reproducibility\n",
        "\n",
        "e.g., as defined by from https://reproducible-builds.org/:\n",
        "\n",
        "> Reproducible builds are a set of software development practices that create a verifiable path from human readable source code to the binary code used by computers.\n",
        "\nIn the context of data analysis, this means having a verifiable path from the raw data to the results reported in a paper."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule 1: For Every Result, Keep Track of How It Was Produced"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "> By ... specifying the full\n",
        "analysis workflow in a form that allows for\n",
        "direct execution, one can ensure that the\n",
        "specification matches the analysis that was\n",
        "(subsequently) performed, and that the\n",
        "analysis can be reproduced by yourself or\n",
        "others in an automated way."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recording your analyses in a Jupyter notebook, for instance, is an excellent way to follow this rule."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule 2: Avoid Manual Data Manipulation Steps"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "This one is simple. If you did it by hand and weren't recording everything you did, how will anyone else reproduce it. And for digital data, if you were recording everything you did, why not record it in a way that allows you to automate the analysis?\n",
        "\nTo follow this rule, you could record *all* your analysis steps in a Jupyter notebook, calling out to external scripts when necessary."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule 3: Archive the Exact Versions of All External Programs Used"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recording the version of external programs is important because different versions of software can behave differently. In Python, a key tool is the requirements file, often named `requirements.txt`.\n",
        "\n",
        "**Exercise**: Create a `requirements.txt` file that specifies pandas version 0.20.2 and requests version 2.18.1.\n",
        "\nSome requirements aren't Python modules and can't be specified in a requirements.txt file. For those, you might want to check out [Docker](https://www.docker.com/)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule 4: Version Control All Custom Scripts\n",
        "\n",
        "Any code you write should be versioned so that you can keep track of the exact code that was run to produce experimental results and analyses. A common technique is to copy and paste the entire analysis pipeline into a new directory, appending a unique identifier such as `analysis_NEW` for version 2, `analysis_NEWNEW` for version 3, etc. Though it's certainly better than nothing, this tends to produce a mess of easily confusable directories (see 9 below), bloated directories, and inconsistencies when bugs are fixed in one version but not the others.\n",
        "\nInstead, use a proper version control system. As of 2017, it's worth starting with [Git](https://git-scm.com/), a standard. The learning curve is particularly shallow, so you may consider starting with an interactive training tool like [`githug`](https://github.com/Gazler/githug) that will run you through the basics quickly. A good first goal would be to learn the vocabulary: repository, clone, stage, commit, push, pull, origin, master, remote, local, merge, and rebase."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule 5: Record All Intermediate Results, When Possible in Standardized Formats\n",
        "\n",
        "> In principle, as long as the full process used to produce a given result is tracked, all intermediate data can also be regenerated. In practice, having easily accessible intermediate results may be of great value.\n",
        "\n**Exercise**: Think of an example of an intermediate result, either in your own work or from one of this week's tutorials, that could profitably be recorded rather than recomputed anew each time. Which storage formats might be appropriate?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule 6: For Analyses That Include Randomness, Note Underlying Random Seeds"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Many experiments in the behavioral and social sciences make use of randomness: e.g., to assign participants to conditions. Most modern programming languages have good support for random number generation, care must be taken to ensure reproducibility. Two things can go wrong â€” first, you can fail to record the seed, losing information needed to reproduce the experiment or analysis exactly; second, you can fail to change the seed when you do want a fresh batch of random numbers. \n",
        "\nSetting the seed in Python is simple:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\nrandom.seed(19145822646)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's generate some random numbers:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "r = [random.random() for _ in range(10)]\n",
        "r"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": [
              "[0.7764387061390589,\n",
              " 0.642291262684286,\n",
              " 0.391831358886754,\n",
              " 0.7916397779561769,\n",
              " 0.13015380897795403,\n",
              " 0.9518298935760082,\n",
              " 0.326529667693343,\n",
              " 0.015399332301525126,\n",
              " 0.7547546949053473,\n",
              " 0.9290506858367827]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll set the seed to the same value to confirm we can recreate the same random numbers:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(19145822646)\n",
        "r2 = [random.random() for _ in range(10)]\n",
        "r2"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": [
              "[0.7764387061390589,\n",
              " 0.642291262684286,\n",
              " 0.391831358886754,\n",
              " 0.7916397779561769,\n",
              " 0.13015380897795403,\n",
              " 0.9518298935760082,\n",
              " 0.326529667693343,\n",
              " 0.015399332301525126,\n",
              " 0.7547546949053473,\n",
              " 0.9290506858367827]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Are they the same?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "r == r2"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. And if you compare with a friend, you'll see that they generated the same numbers, too."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule 7: Always Store Raw Data behind Plots\n",
        "\nEven better, always store the raw data. And you can version your data, too, perhaps by commiting it to a version-control system like Git or the [Open Science Framework](https://osf.io/)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule 8: Generate Hierarchical Analysis Output, Allowing Layers of Increasing Detail to Be Inspected\n",
        "\n",
        "> When the storage context allows, it is\n",
        "better to simply incorporate permanent\n",
        "output of all underlying data when a\n",
        "main result is generated, using a systematic\n",
        "naming convention to allow the full\n",
        "data underlying a given summarized\n",
        "value to be easily found. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule 9: Connect Textual Statements to Underlying Results\n",
        "\n",
        "> Throughout a typical research project, a\n",
        "range of different analyses are tried and\n",
        "interpretation of the results made... If you want to reevaluate your previous\n",
        "interpretations, or allow peers to\n",
        "make their own assessment of claims you\n",
        "make in a scientific paper, you will have\n",
        "to connect a given textual statement\n",
        "(interpretation, claim, conclusion) to the\n",
        "precise results underlying the statement.\n",
        "\nA Jupyter notebook enables you to put explanations and code side by side, following the recommendations above."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule 10: Provide Public Access to Scripts, Runs, and Results\n",
        "\n",
        "> Last, but not least, all input data,\n",
        "scripts, versions, parameters, and intermediate\n",
        "results should be made publicly\n",
        "and easily accessible.\n",
        "\n",
        "Check out the [Open Science Framework](https://osf.io/).\n",
        "\n**DISCUSSION** What are some of the limitations to sharing behavioral and social science data? Has this affected your work?"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "language": "python",
      "display_name": "Python 2"
    },
    "kernel_info": {
      "name": "python2"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.13",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}