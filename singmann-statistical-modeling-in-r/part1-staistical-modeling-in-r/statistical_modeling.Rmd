---
title: "Statistical Modeling in R"
subtitle: "The Basics"
author: "Henrik Singmann (University of Zurich)<br/>Twitter: <a href='https://twitter.com/HenrikSingmann'>@HenrikSingmann</a>"
date: "June 2017"
output:
  xaringan::moon_reader:
    css: ["default", "my-theme.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9'
---



```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
# see: https://github.com/yihui/xaringan
# install.packages("xaringan")
# see: 
# https://github.com/yihui/xaringan/wiki
# https://github.com/gnab/remark/wiki/Markdown
options(width=110)
options(digits = 4)
```

# Statistical Model

From [Wikipedia](https://en.wikipedia.org/wiki/Statistical_model) (emphasis added):

> A statistical model is a class of mathematical model, which embodies a set of assumptions concerning the generation of some sample data, and similar data from a larger population. A statistical model represents, often in considerably idealized form, the **data-generating process**.

> The assumptions embodied by a statistical model describe a set of **probability distributions**, some of which are assumed to adequately approximate the distribution from which a particular data set is sampled. The probability distributions inherent in statistical models are what distinguishes statistical models from other, non-statistical, mathematical models.

> A statistical model is usually specified by mathematical equations that relate one or more random variables and possibly other non-random variables. As such, "a model is a formal representation of a theory" (Herman Ader quoting Kenneth Bollen).

> All statistical hypothesis tests and all statistical estimators are derived from statistical models. More generally, statistical models are part of the foundation of statistical inference.

---
class: small

# Some Example Data

Data from Revelle, Wilt and Rosenthal (2009). `?sat.act`:
> Items were collected as part of the SAPA project (http://sapa-project.org) to develop online measures of ability (Revelle, Wilt and Rosenthal, 2009). The score means are higher than national norms suggesting both self selection for people taking on line personality and ability tests and a self reporting bias in scores.

```{r, message=FALSE}
require(psych)
data(sat.act)
sat.act$gender <- factor(sat.act$gender, 1:2, labels = c("male", "female"))
sat.act$education <- factor(sat.act$education)
summary(sat.act) # alternatively: psych::describe(sat.act)
sat.act <- na.omit(sat.act)
```

---
# Some Example Data


```{r, fig.height=4, dev='svg'}
par(mfrow=c(1,2))
plot(sat.act$SATV, sat.act$ACT)
plot(sat.act$SATQ, sat.act$ACT)
```

---
# Linear Regression Model

- $\bf{y}$ = vector of ACT scores of length $n$ (*dependent variable*)
- $\bf{x_{\mbox{SATV}}}$ = vector of SATV scores of length $n$ (*independent variable* or *covariate*)

$$y_i = \beta_0x_{0,i}+\beta_{\mbox{SATV}}x_{\mbox{SATV},i}+\epsilon_i, \ \ i = 1, ..., n, \\
\bf{\epsilon} \sim \mathcal{N}(0, \sigma^2_{\epsilon}),$$
where $\bf{x_0}$ is a vector of 1s of length $n$.

- Errors $\bf{\epsilon}$ are assumed to come from a normal distribution (i.e., uncorrelated).

- $\beta_0$ and  $\beta_{\mbox{SATV}}$ are scalars (i.e., of length 1) and called *regression coefficients* or *parameters* ( $\sigma^2_{\epsilon}$ is also a parameter). $\beta_0$ is also known as the *intercept*.

******

In matrix form this model can be expressed as:
$$\bf{y} = \bf{X}\bf{\beta}+\bf{\epsilon}$$

---
class: small

# Linear Model in R

.pull-left2[
```{r}
m1 <- lm(ACT ~ SATQ, sat.act)
summary(m1)
```

]
.pull-right2[
```{r}
coef(m1)
```

```{r, fig.height=3.7, fig.width=4, dev='svg'}
plot(sat.act$SATV, sat.act$ACT)
abline(m1)
```
]
---
class: small

# Linear Model in R (Centered)

.pull-left2[
```{r}
sat.act$SATQ_c <- sat.act$SATQ - mean(sat.act$SATQ, na.rm = TRUE)
sat.act$SATV_c <- sat.act$SATV - mean(sat.act$SATV)
m2 <- lm(ACT ~ SATQ_c, sat.act)
summary(m2)
```

]
.pull-right2[
```{r}
coef(m2)
```

```{r, fig.height=3.7, fig.width=4, dev='svg'}
plot(sat.act$SATV_c, sat.act$ACT)
abline(m2)
```
]
---

class: inline-grey
# Formula Interface for Statistical Models: `~`

Allows symbolic specification of statistical model, e.g. linear models: `lm(ACT ~ SATQ, sat.act)`

Everything to the left of `~` is the dependent variable:
```r
y ~ x # univariate model
cbind(y1, y2, y3) ~ x # multivariate model
~ x # one sided formula
```

Independent variables are to the right of the `~`:

| Formula | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | Interpretation  |
| ------------------------|---|----------------------------------|
| `~ x` or `~1+x`         || Intercept and main effect of `x` | 
| ` ~ x-1` or `~0 + x`    || Only main effect of `x` and no intercept (questionable) |
| `~ x+y`                 || Main effects of `x` and `y`|
| `~ x:y`                 || Interaction between `x` and `y` (and no main effect) |
| `~ x*y` or `~ x+y+x:y`  || Main effects and interaction between `x` and `y` |

---
class: small

# How many Parameters in each Model?

```{r, eval=FALSE}
lm(ACT ~ SATQ_c + SATV_c, sat.act)   # a
lm(ACT ~ SATQ_c : SATV_c, sat.act)   # b
lm(ACT ~ 0 + SATQ_c:SATV_c, sat.act) # c
lm(ACT ~ SATQ_c*SATV_c, sat.act)     # d
lm(ACT ~ 0+SATQ_c*SATV_c, sat.act)   # e
```

--
.pull-left[
```{r}
coef(lm(ACT ~ SATQ_c + SATV_c, sat.act))   # a
coef(lm(ACT ~ SATQ_c : SATV_c, sat.act))   # b
coef(lm(ACT ~ 0 + SATQ_c:SATV_c, sat.act)) # c
```


]

.pull-right[
```{r}
coef(lm(ACT ~ SATQ_c*SATV_c, sat.act))     # d
coef(lm(ACT ~ 0+SATQ_c*SATV_c, sat.act))   # e
```

]

```{r, eval=FALSE, include=FALSE}
summary(lm(ACT ~ SATQ + SATV, sat.act))   # a
summary(lm(ACT ~ SATQ : SATV, sat.act))   # b
summary(lm(ACT ~ 0 + SATQ:SATV, sat.act)) # c
summary(lm(ACT ~ SATQ*SATV, sat.act))     # d
summary(lm(ACT ~ 0+SATQ*SATV, sat.act))   # e
```


---
class: center, middle, inverse

# Categorical Covariates

---
class: small
# Categorical Covariates

`R` modeling functions behave differently for numerical and categorical covariates. 

It is important to always know of what type variables are. Use `str()` on a `data.frame` to obtain information regarding the structure, including variable types: 

```{r}
str(sat.act)
```

- Numerical covariates are `int` or `num`.
- Categorical covariates are `Factor` (or `character`).

**Make sure all categorical variables are factors before adding them to a statistical model!**

---
class: small

# Models with Categorical Covariates

We might be interested in testing whether ACT differs between men and women. 
.pull-left2[
```{r}
m3 <- lm(ACT ~ gender, sat.act)
summary(m3)
```

]
--

```{r, include=FALSE}
op <- options(width = 40)
require(dplyr)
```

.pull-right2[
```{r}
mean(sat.act$ACT)
sat.act %>% group_by(gender) %>%
  summarise(m = mean(ACT))
```

```{r}
sat.act %>% group_by(gender) %>%
  summarise(m = mean(ACT)) %>%
  {.$m[2] - .$m[1]}
```
]

```{r, include=FALSE}
options(op)
```

---
class: small

# R and Categorical Covariates
`model.matrix()` transforms categorical covariates into numerical variables that can be used for fitting using a specific contrast function (see `?contr.sum`).

.pull-left[
```{r}
model.matrix(ACT ~ gender, sat.act[1:5,])
```
]

---
class: small
# R and Categorical Covariates

`model.matrix()` transforms categorical covariates into numerical variables that can be used for fitting using a specific contrast function (see `?contr.sum`).

.pull-left[
```{r}
model.matrix(ACT ~ gender, sat.act[1:5,])
```

```{r}
afex::set_sum_contrasts()
```

]

.pull-right[
```{r}
model.matrix(ACT ~ gender, sat.act[1:5,])
```
]

---
class: small

# Models with Categorical Covariates II 

Same model as before, but with sum/effects contrasts.

.pull-left2[
```{r}
m4 <- lm(ACT ~ gender, sat.act)
summary(m4)
```

]

```{r, include=FALSE}
op <- options(width = 40)
```

.pull-right2[
```{r}
mean(sat.act$ACT)
sat.act %>% group_by(gender) %>%
  summarise(m = mean(ACT))
sat.act %>% group_by(gender) %>%
  summarise(m = mean(ACT)) %>% 
  summarise(mean(m))

```

]

```{r, include=FALSE}
options(op)
```

---
class: small
# Models with Categorical Covariates and Interactions

```{r}
afex::set_default_contrasts() # or set_treatment_contrasts()
```


```{r, include=FALSE}
op <- options(width = 70)
```

.pull-left2[
```{r}
m5 <- lm(ACT ~ gender*education, sat.act)
coef(m5)
```

]

.pull-right2[
```{r}
sat.act %>% 
  group_by(gender,education) %>%
  summarise(mean(ACT))
```
]

```{r, include=FALSE}
options(op)
```

---
class: small
# Models with Categorical Covariates and Interactions II

```{r}
afex::set_sum_contrasts() # or set_effects_contrasts() or set_deviation_contrasts()
```


```{r, include=FALSE}
op <- options(width = 70)
```

.pull-left2[
```{r}
m6 <- lm(ACT ~ gender*education, sat.act)
coef(m6)
```

]

.pull-right2[
```{r}
sat.act %>% 
  group_by(gender,education) %>%
  summarise(m = mean(ACT)) %>% 
  ungroup() %>% 
  summarise(mean(m))
```
]

```{r, include=FALSE}
options(op)
```

---
# Categorical Covariates and Model Matrices

.pull-left3[
```{r, eval=FALSE}
lm(ACT ~ SATQ + SATV, sat.act)   # a: 3
lm(ACT ~ SATQ : SATV, sat.act)   # b: 2
lm(ACT ~ 0 + SATQ:SATV, sat.act) # c: 1
lm(ACT ~ SATQ*SATV, sat.act)     # d: 4
lm(ACT ~ 0+SATQ*SATV, sat.act)   # e: 3

lm(ACT ~ SATQ, sat.act)          # f: 2
lm(ACT ~ 0 + SATQ, sat.act)      # g: 1
```

]

--
.pull-right3[
```{r, eval=FALSE}
lm(ACT ~ gender, sat.act)                  # a
lm(ACT ~ 0+gender, sat.act)                # b
lm(ACT ~ gender+education, sat.act)        # c
lm(ACT ~ 0+gender+education, sat.act)      # d
lm(ACT ~ gender:education, sat.act)        # e
lm(ACT ~ 0+gender:education, sat.act)      # f
lm(ACT ~ gender*education, sat.act)        # g
lm(ACT ~ 0+gender*education, sat.act)      # h
lm(ACT ~ gender+gender:education, sat.act) # i
```

```{r}
levels(sat.act$gender)
levels(sat.act$education)
```


]


---
class: small

# Beware of Formulas with Categorical Variables


```{r}
coef(lm(ACT ~ gender, sat.act))                  # a: 2
coef(lm(ACT ~ 0+gender, sat.act))                # b: 2
coef(lm(ACT ~ gender+education, sat.act))        # c: 7
coef(lm(ACT ~ 0+gender+education, sat.act))      # d: 7
```

---
class: small


```{r}
coef(lm(ACT ~ gender:education, sat.act))        # e: 13
coef(lm(ACT ~ 0+gender:education, sat.act))      # f: 12
```

```{r, eval = FALSE}
coef(lm(ACT ~ gender*education, sat.act))        # g: 12
coef(lm(ACT ~ 0+gender*education, sat.act))      # h: 12
coef(lm(ACT ~ gender+gender:education, sat.act)) # i: 12
```



---
class: inline-grey
# Interim Summary

- The `R` `formula` interface allows symbolic specification of statistical models.
  - `+` = main effects
  - `:` = interaction
  - `*` = main effects plus interaction
  - `0+`/`-1` = no intercept

- Categorical variables are transformed into numerical variables using contrast functions (via `model.matrix()`; see Cohen et al., 2002)
  - If models include interactions, orthogonal contrasts (e.g., `contr.sum`) in which the intercept corresponds to the (unweighted) grand mean should be used: `afex::set_sum_contrasts()`
  - Dummy/treatment contrasts (`R` default) lead to simple effects for lower order effects.
  - **Coding only affects interpretation of parameters/tests not overall model fit.**

- For models with only numerical covariates, suppressing intercept works as expected.
- For models with categorical covariates, suppressing intercept or other lower-order effects often leads to very surprising results (and should generally be avoided).

---
class: center, middle, inverse

# Tests of Terms/Effects

---
class: small

```{r, include=FALSE}
op <- options(width = 70)
```

.pull-left2[
```{r, message=FALSE}
afex::set_sum_contrasts()
m6 <- lm(ACT ~ gender*education, sat.act)
summary(m6)
```

]

.pull-right2[
```{r}
sat.act %>% 
  group_by(gender, education) %>%
  summarise(m = mean(ACT)) %>% 
  ungroup() %>% 
  summarise(mean(m))
```
]

```{r, include=FALSE}
options(op)
```

---

# `car::Anova()` is the Solution

```{r, message=FALSE}
require(car) # Companion to Applied Regression (Fox & Weisberg, 2011)
Anova(m6, type = 3)
```
--

- Type II and III tests equivalent for balanced designs (i.e., equal group sizes) and highest-order effect.
- Type III tests require orthogonal contrasts (e.g.,`contr.sum`); recommended:
  - For experimental designs in which imbalance is completely random and not structural,
  - Complete cross-over interactions (i.e., main effects in presence of interaction) possible.
- Type II are more appropriate if imbalance is structural (i.e., observational data; maybe here).

---
class: small, inline-grey

# `lsmeans()` Solution for Follow-Up/Post-Hoc Tests

.pull-left[
```{r, message=FALSE, warning=FALSE}
require(lsmeans)
lsmeans(m6, ~education)
```
`lsmeans` returns estimated marginal means (or least-square means for linear regression) for model terms (e.g., `lsmeans(m6, ~education*gender)`).

One can specify arbitrary contrasts on marginal means (e.g., `contrast()`).

]
--
.pull-right[
```{r, message=FALSE}
pairs(lsmeans(m6,~education),adjust='holm')
```
]

---
class: inline-grey
# Beyond Linear Models with Normal Residual Distribution

Statistical models defined by relationship of covariates and assumption of residual probability distribution. `formula` defines the relationship of covariates, `function` defines distributional assumption.

Most models assume independent data points (i.e., no replicates or repeated measures):  
- `lm()` linear model (normal distribution of residuals, includes multivariate IVs)
- `glm()` generalized linear model (other residual distribution, e.g., binomial, Poisson)
- `MASS::rlm()` robust linear model
- `MASS::polr()` ordered logistic or probit regression
- `MASS::loglm()` log-linear model (for contingency tables)
- `nnet::multinom()` models for multinomial data

Functions supporting repeated-measures usually require more complicated formulas/model specification:  
- `nlme::lme()` linear mixed-effects models (generally superseded by `lme4`)
- `lme4::lmer()` linear mixed-effects models (modern implementation)
- `lme4::glmer()` generalized linear mixed-effects models
- `mcmcGLMM` Bayesian generalized linear mixed-effects models
- `rstan::stan_lmer()`/`rstan::stan_glmer()` Bayesian (generalized) linear mixed-effects models

---
class: inline-grey
# Summary: Analysis with Statistical Models in R

1. Identify probability distribution of data (or better: residuals/conditional distribution)
2. Make sure variables are of correct type via `str()`
3. Set appropriate contrasts (orthogonal contrasts if model includes interaction): `afex::set_sum_contrasts()`
4. Describe statistical model using `formula`
4. Fit model: pass `formula` and `data.frame` to corresponding modeling function (e.g., `lm()`, `glm()`)
4. Check model fit (e.g., inspect residuals)
5. Test terms (i.e., main effects and interactions): Pass fitted model to `car::Anova()`
7. Follow-up tests: 
   - Estimated marginal means: Pass fitted model to `lsmeans::lsmeans()`
   - Specify specific contrasts on estimated marginal means (e.g., `contrast()`, `pairs()`)

--

`afex` combines fitting (5.) and testing (7.):
- ANOVAs: `afex::aov_car()`, `afex::aov_ez()`, or `afex::aov_4()`
- (Generalized) linear mixed-effects models: `afex::mixed()`

---
class: small
# ANOVAs with afex

.pull-left[
`afex::aov_car()` allows specification of ANOVA using formula, but requires specification of participant id in `Error()` term.

```{r, message=FALSE, comment='#'}
require(afex)
sat.act$id <- factor(1:nrow(sat.act))
(a1 <- aov_car(ACT ~ gender+Error(id), sat.act))

```
```{r}
sat_long <- tidyr::gather(
  sat.act, key = "SAT_type", 
  value = "SAT_value", SATV, SATQ)
```

]

--
.pull-right[

```{r, message=FALSE, comment='#'}
(a2 <- aov_car(SAT_value ~ gender*SAT_type+
                 Error(id/SAT_type), sat_long))
lsmeans(a2, c("gender", "SAT_type"))
```

]

---
class: center, middle, inverse

# Repeated-Measures

---
class: inline-grey
# IID Assumption

- Ordinary linear regression, between-subjects ANOVA, and basically all standard statistical models share one assumption: Data points are *independent and identically distributed* (*iid*).
  - Independence assumption refers to residuals: After taking structure of model (i.e., parameters) into account, probability of a data point having a specific value is independent of all other data points.
  - Identical distribution: All observations sampled from same distribution.

- For repeated-measures independence assumption often violated (e.g., data points from one participant more likely to be similar to each other).
- Violation of independence assumption can have dramatic consequences on statistical inferences from a model (e.g., increased or decreased Type I errors).

- Three ways to deal with repeated-measures:
  1. *Complete pooling*: Ignore dependency in data (often not appropriate, results likely biased, not trustworthy)
  2. *No pooling*: Separate data based on factor producing dependency and calculate separate statistical model for each subset (combining results can be non-trivial)
  3. *Partial pooling*: Analyse data jointly while taking dependency into account (gold standard, e.g., mixed models)

---
class: small

# Example Data 2

![](cognition_cutout.png)


---
class: small

# Skovgaard-Olsen et al. (2016)

- Conditional = *if-then* statement; e.g., If global warning continues, London will be flooded.
- Bayesian reasoning often assumes 'the Equation': *P*(if *A* then *B*) = *P*(*B*|*A*)
- Our question: Does the Equation hold even if no apparent relationship between *A* and *B*? 
  - positive relevance (PO): *A* is a reason for *B* 
  - negative relevance (NE): *A* is a reason against *B* 
  - irrelevance (IR): *A* and *B* have no apparent relationship 

- 348 participants recruited via `crowdflower.com` worked on 12 items:
  > Sophia's scenario: Sophia wishes to find a nice present for her 13-year-old son, Tim, for Christmas. She is running on a tight budget, but she knows that Tim loves participating in live role-playing in the forest and she is really skilled at sewing the orc costumes he needs. Unfortunately, she will not be able to afford the leather parts that such costumes usually have, but she will still be able to make them look nice.

--

  > Suppose Sophia buys a Barbie doll for Tim.   
  > Under this assumption, how probable is it that the following sentence is true:   
  > Tim will be excited about his present.

--

  > Could you please rate the probability that the following sentence is true:   
  > IF Sophia buys a Barbie doll for Tim, THEN Tim will be excited about his present.


---
class: small

### Skovgaard-Olsen et al. (2016)

- Does the Equation (i.e., *P*(if *A* then *B*) = *P*(*B*|*A*)) hold even if no apparent relationship between *A* and *B*? 
  - positive relevance (PO): *A* is a reason for *B* 
  - negative relevance (NE): *A* is a reason against *B* 
  - irrelevance (IR): *A* and *B* have no apparent relationship 

- For each item, participants provide idiosyncratic estimates of *P*(if *A* then *B*) and *P*(*B*|*A*).
- Each participant worked on 12 items, 4 per relevance condition (i.e., a 4 x 3 within-subjects design)
- Type of DV is between-subjects condition: 
  - Probability of 'if *A* then *C*': How probable is 'if *A* then *C*'?
  - Acceptability of 'if *A* then *C*': How acceptable is it to say 'if *A* then *C*'?).

- Data available at: https://osf.io/j4swp/

--

### Exercise 1: Analyse the data using the no-pooling approach.
- Calculate the regression between *P*(if *A* then *B*) and *P*(*B*|*A*) separately for each participant and within-subjects condition.
- Does this analysis yield some interpretable differences in the regression coefficients between the conditions?
- For precise instructions see: `exercises/exercise_1.Rmd`

---
### References Statistical Modeling:
- John Fox and Sanford Weisberg (2011). *An R Companion to Applied Regression, Second Edition.* Thousand Oaks CA: Sage. URL: http://socserv.socsci.mcmaster.ca/jfox/Books/Companion
- Russell V. Lenth (2016). Least-Squares Means: The R Package lsmeans. *Journal of Statistical
  Software*, 69(1), 1-33. https://doi.org/10.18637/jss.v069.i01
- Cohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2002). *Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences.* New York: Routledge Academic.

### References Example Data:
- Revelle, William, Wilt, Joshua, and Rosenthal, Allen (2009) Personality and Cognition: The Personality-Cognition Link. In Gruszka, Alexandra and Matthews, Gerald and Szymura, Blazej (Eds.) _Handbook of Individual Differences in Cognition: Attention, Memory and Executive Control_, Springer.
- Skovgaard-Olsen, N., Singmann, H., & Klauer, K. C. (2016). The relevance effect and conditionals. *Cognition*, 150, 26-36. https://doi.org/10.1016/j.cognition.2015.12.017
