<!DOCTYPE html>
<html>
  <head>
    <title>Mixed Models in R</title>
    <meta charset="utf-8">
    <meta name="author" content="Henrik Singmann (University of Zurich) Twitter: @HenrikSingmann" />
    <link href="libs/remark-css/example.css" rel="stylesheet" />
    <link rel="stylesheet" href="my-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Mixed Models in R
## A Practical Introduction
### Henrik Singmann (University of Zurich)<br/>Twitter: <a href='https://twitter.com/HenrikSingmann'><span class="citation">@HenrikSingmann</span></a>
### June 2017

---






# Mixed Models

- Mixed models are a modern class of statistical models that extend regular regression models by including random effects parameters to account for dependencies among related data points.

--

.pull-left[

### Fixed Effects
- Overall  or *population-level average* effect of specific model term (i.e., main effect, interaction, parameter) on dependent variable
- Independent of stochastic variability controlled for by random effects
- Hypothesis tests on fixed effect interpreted as hypothesis tests for terms in standard ANOVA or regression model
- Possible to test specific hypotheses among factor levels (e.g., planned contrasts)

]

.pull-right[
### Random Effects

- *Random-effects grouping factors*: Categorical variables that capture random or stochastic variability (e.g., participants, items, groups, or other hierarchical-structures).
- In experimental settings, random effects grouping factors often part of design one wants to generalize over.
- Random effects factor out idiosyncrasies of sample, thereby providing a more general estimate of the fixed effects of interest.
- *Random-effects parameters*: Provide each level of random effect grouping factor with idiosyncratic parameter set.

]

---
class:small




# Example Data

Reduced data of Skovgaard-Olsen et al. (2016):
- 2 relevance conditions: positive and negative
- No between-subjects condition (only probability question)

.pull-left[


```r
m_fixed &lt;- lm(dv ~ c_given_a*rel_cond, datr)
summary(m_fixed)
```

```
## 
## Call:
## lm(formula = dv ~ c_given_a * rel_cond, data = datr)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.6951 -0.0914 -0.0090  0.0611  0.8155 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         -0.06965    0.00902   -7.72  3.8e-14 ***
## c_given_a            0.62031    0.02441   25.41  &lt; 2e-16 ***
## rel_cond1            0.14790    0.00902   16.39  &lt; 2e-16 ***
## c_given_a:rel_cond1  0.16725    0.02441    6.85  1.5e-11 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.235 on 748 degrees of freedom
## Multiple R-squared:  0.637,	Adjusted R-squared:  0.635 
## F-statistic:  437 on 3 and 748 DF,  p-value: &lt;2e-16
```
]
.pull-right[

![](mixed_models_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;

`$$y=\beta_0 + \beta_{C|A}X_{C|A} + \beta_{r}X_{r} + \beta_{I}X_{I} + \epsilon$$`

]

---
class: small

.pull-left[
### Fixed Effects Model

`$$y=\beta_0 + \beta_{C|A}X_{C|A} + \beta_{r}X_{r} + \beta_{I}X_{I} + \epsilon$$`

- `\(\beta\)` are scalar regression parameters
- `\(X\)` are covariate vectors (numerical independent variables with -1 and 1 for factors)
- assumes error vector `\(\epsilon\)` is *iid*, `\(\epsilon \sim \mathcal{N}(0, \sigma^2_{\epsilon})\)`, which is likely false.
]

.pull-right[
![](mixed_models_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;
]

--

### A First Mixed Effects Model

`$$y=\beta_0 + (\beta_{C|A}+ S_{C|A})X_{C|A} + \beta_{r}X_{r} + \beta_{I}X_{I} + \epsilon$$`
- `\(S_{C|A}\)` is a zero-centered vector of participant specific random effects: `\(S_{C|A} \sim \mathcal{N}(0, \sigma^2_{S_{C|A}})\)`
- `\(S_{C|A}\)` provides each participant with their own regression weight: overall `\(\beta_{C|A}\)` plus idiosyncratic `\(S_{C|A}\)`.
- As parameter, model estimates variance of random effects vector, `\(\sigma^2_{S_{C|A}}\)`.
- As `\(S_{C|A}\)` alters the regression slope `\(\beta_{C|A}\)`, also known as *random slope*.
- In `lme4::lmer` syntax: `lmer(dv ~ c_given_a*rel_cond + (0+c_given_a|p_id), datr)`

---
class: small


.pull-left[
### Fixed Effects Model

`$$y=\beta_0 + \beta_{C|A}X_{C|A} + \beta_{r}X_{r} + \beta_{I}X_{I} + \epsilon$$`

- `\(\beta\)` are scalar regression parameters
- `\(X\)` are covariate vectors (numerical independent variables with -1 and 1 for factors)
- assumes error vector `\(\epsilon\)` is *iid*, `\(\epsilon \sim \mathcal{N}(0, \sigma^2_{\epsilon})\)`, which is likely false.
]

.pull-right[
![](mixed_models_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;
]

### A First Mixed Effects Model

`$$y=\beta_0 + (\beta_{C|A}+ S_{C|A})X_{C|A} + \beta_{r}X_{r} + \beta_{I}X_{I} + \epsilon$$`
- `\(S_{C|A}\)` is a zero-centered vector of participant specific random effects: `\(S_{C|A} \sim \mathcal{N}(0, \sigma^2_{S_{C|A}})\)`
- `\(S_{C|A}\)` provides each participant with their own regression weight: overall `\(\beta_{C|A}\)` plus idiosyncratic `\(S_{C|A}\)`.
- As parameter, model estimates variance of random effects vector, `\(\sigma^2_{S_{C|A}}\)`.
- As `\(S_{C|A}\)` alters the regression slope `\(\beta_{C|A}\)`, also known as *random slope*.
- In `lme4::lmer` syntax: `lmer(dv ~ c_given_a*rel_cond + (0+c_given_a|p_id), datr)`


---
class: small

### A More Reasonable Mixed Model

First model did not allow for different intercepts, `\(\beta_0\)`, for each participant. 

`$$y=\beta_0 + S_0 + (\beta_{C|A}+ S_{C|A})X_{C|A} + \beta_{r}X_{r} + \beta_{I}X_{I} + \epsilon$$`
- Model now has a random intercept, `\(S_0\)`, and a random slope, `\(S_{C|A}\)`.
- `\(S\)`-vectors still zero-centered vectors of participant specific random effects. However, we now estimate both, variance and covariance of random effects:
  
`$$\left( \begin{matrix} S_0 \\ S_{C|A} \end{matrix} \right)
 \sim \mathcal{N}\left( \left[ \begin{matrix} 0 \\ 0 \end{matrix} \right] , \left[ \begin{matrix} \sigma^2_{S_0}&amp;\rho_{S_{0},S_{C|A}}\sigma_{S_{0}}\sigma_{S_{C|A}} \\ \rho_{S_{C|A},S_{0}}\sigma_{S_{0}}\sigma_{S_{C|A}}&amp;\sigma^2_{S_{C|A}} \end{matrix} \right] \right)$$`

Each `\(S_i\)` idiosyncratic intercept &amp; slope: `lmer(dv ~ c_given_a*rel_cond + (c_given_a|p_id), datr)`

.pull-left[
![](mixed_models_files/figure-html/unnamed-chunk-6-1.png)&lt;!-- --&gt;
]

---

### Interim Summary

*Fixed-effects parameters*: Overall  effect of specific model term on dependent variable

*Random-effects parameters*: 
- zero-centered offsets/displacements for each level of random effect grouping factor
- added to specific fixed effect parameter
- assumed to follow normal distribution which provides hierarchical shrinkage, thereby avoids over-fitting
- should be added to each parameter that varies within the levels of a random effects grouping factor (i.e., factor is *crossed* with random effects grouping factor)

.pull-left[
![](mixed_models_files/figure-html/unnamed-chunk-7-1.png)&lt;!-- --&gt;
]

.pull-right[
![](mixed_models_files/figure-html/unnamed-chunk-8-1.png)&lt;!-- --&gt;
]

---
class: small
### Maximal By-Participant Mixed Model

`$$y=\beta_0 + S_0 + (\beta_{C|A}+ S_{C|A})X_{C|A} + (\beta_{r}+ S_{r})X_{r} + (\beta_{I}+ S_{I})X_{I} + \epsilon$$`
- Model estimates 4 variances for zero-centered `\(S\)` vectors, 1 residual variance, and 6 correlations among random effects.

--
.pull-left[

```r
require(lme4)
m_p_max &lt;- lmer(dv ~ c_given_a*rel_cond + 
                  (c_given_a*rel_cond|p_id), datr)
summary(m_p_max)$varcor
```

```
##  Groups   Name                Std.Dev. Corr             
##  p_id     (Intercept)         0.122                     
##           c_given_a           0.229     0.14            
##           rel_cond1           0.100    -0.43 -0.96      
##           c_given_a:rel_cond1 0.229    -1.00 -0.14  0.43
##  Residual                     0.154
```

```r
summary(m_p_max)$coefficients
```

```
##                     Estimate Std. Error t value
## (Intercept)         -0.07924    0.01427  -5.553
## c_given_a            0.63016    0.03007  20.954
## rel_cond1            0.15044    0.01229  12.245
## c_given_a:rel_cond1  0.17899    0.02985   5.996
```
]

.pull-right[
![](mixed_models_files/figure-html/unnamed-chunk-10-1.png)&lt;!-- --&gt;
]

---
class: small
## Crossed Random-Effects

So far only considered *participant* as random effects grouping factor:
- Each participant provides several responses: Random-intercept allows idiosyncratic intercept.
- `c_given_a` and `rel_cond` are within-subjects variables: Random-slopes allow idiosyncratic effects.

Participant is only one source of stochastic variability. We usually want to generalize over both *participants* and *items*. 
- Example data: Each participant provides 1 response for each of 12 items with condition randomly selected.
- All factors also vary within-items.

Mixed models allow multiple independent random effects (where `\(I\)` are vectors of item-specific offsets):

`$$y=\beta_0 + S_0 + I_0 + (\beta_{C|A} + S_{C|A} + I_{C|A})X_{C|A} + (\beta_{r} + S_{r}+ I_{r})X_{r} + (\beta_{I}+ S_{I}+ I_{I})X_{I} + \epsilon$$`


```r
m_max &lt;- lmer(dv ~ c_given_a*rel_cond + 
                (c_given_a*rel_cond|p_id) + 
                (c_given_a*rel_cond|i_id), 
              datr)
```


---
class: small


```r
summary(m_max)
```

```
## Linear mixed model fit by REML ['lmerMod']
## Formula: dv ~ c_given_a * rel_cond + (c_given_a * rel_cond | p_id) + (c_given_a *      rel_cond | i_id)
##    Data: datr
## 
## REML criterion at convergence: -387.9
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -5.112 -0.326  0.015  0.259  3.742 
## 
## Random effects:
##  Groups   Name                Variance Std.Dev. Corr             
##  p_id     (Intercept)         0.01622  0.1274                    
##           c_given_a           0.05396  0.2323    0.14            
##           rel_cond1           0.01024  0.1012   -0.44 -0.95      
##           c_given_a:rel_cond1 0.05685  0.2384   -1.00 -0.16  0.46
##  i_id     (Intercept)         0.00116  0.0340                    
##           c_given_a           0.00930  0.0965    0.15            
##           rel_cond1           0.00175  0.0419   -0.12 -1.00      
##           c_given_a:rel_cond1 0.00349  0.0591   -1.00 -0.13  0.10
##  Residual                     0.02095  0.1447                    
## Number of obs: 752, groups:  p_id, 94; i_id, 12
## 
## Fixed effects:
##                     Estimate Std. Error t value
## (Intercept)          -0.0765     0.0177   -4.33
## c_given_a             0.6262     0.0411   15.24
## rel_cond1             0.1535     0.0173    8.88
## c_given_a:rel_cond1   0.1681     0.0350    4.81
## 
## Correlation of Fixed Effects:
##             (Intr) c_gvn_ rl_cn1
## c_given_a    0.086              
## rel_cond1   -0.225 -0.888       
## c_gvn_:rl_1 -0.881 -0.096  0.194
```

---
class:small

### Effect of Partial-Pooling / Hierarchical Shrinkage / Regularization



.pull-left[

Comparison of no-pooling and partial-pooling (i.e., LMM) estimates for `c_given_a` slopes:

&lt;img src="mixed_models_files/figure-html/unnamed-chunk-14-1.png" width="500px" height="300px" /&gt;

]


.pull-right[

Distribution of no-pooling and partial-pooling (i.e., LMM) estimates for `c_given_a` slopes:

&lt;img src="mixed_models_files/figure-html/unnamed-chunk-15-1.png" width="400px" height="350px" /&gt;
]

- If individual effects can be assumed to come from one normal distribution, partial-pooling provides better estimates than no-pooling even on the individual level (at least on average).
- a.k.a. *James-Stein Estimation* (e.g., Efron &amp; Hastie, 2016, ch. 7) or *Stein's phenomenon*, more generally *regularization*: *ridge regression*, *lasso*, *penalized least squares*, *penalized likelihood*, ...

---
class:small

&lt;img src="mixed_models_files/figure-html/unnamed-chunk-16-1.png" width="1000px" height="500px" /&gt;

- from Tristan Mahr: https://tjmahr.github.io/plotting-partial-pooling-in-mixed-effects-models/


---
class: small
### Types of Random Effects

![](random_effect_types.png)

---
class: small

# Hypothesis-Tests for Mixed Models

`lme4::lmer` does not include *p*-values.

`afex::mixed` provides four different methods:
1. Kenward-Roger (`method="KR"`, default): Provides best-protection against anti-conservative results, requires a lot of RAM for complicated random-effects structures.
2. Satterthwaite (`method="S"`): Similar to KR, but requires less RAM.
3. Parametric-bootstrap (`method="PB"`): Simulation-based, can take a lot of time (can be speed-up using parallel computation).
4. Likelihood-ratio tests (`method="LRT"`): Provides worst control for anti-conservative results. Can be used if all else fails or if all random effects grouping factors have large numbers of levels (e.g., over 50).

Methods do not differ for example data:


```r
require(afex)
mixed(dv ~ c_given_a*rel_cond + (c_given_a*rel_cond|p_id), datr, method = "KR") 
mixed(dv ~ c_given_a*rel_cond + (c_given_a*rel_cond|p_id), datr, method = "S") 
mixed(dv ~ c_given_a*rel_cond + (c_given_a*rel_cond|p_id), datr, method = "LRT") 
# mixed(dv ~ c_given_a*rel_cond + (c_given_a*rel_cond|p_id), datr, method = "PB") 
```

---
class:small

# Specifying Random-Effects Structure

- Omitting random-effects parameters for model terms which vary within the levels of a random-effects grouping factor and for which random variability exists leads to non-iid residuals (i.e., `\(\epsilon\)`) and anti-conservative results (e.g., Barr, Levy, Scheepers, &amp; Tily, 2013).
- Safeguard is *maximal model justified by the design*.
- If maximal model is overparameterized and/or contains degenerate estimates or singular fits, power of maximal model can be severely reduced and a reduced model should be used (Bates et al., 2015; Matuschek et al., 2017).

Steps for running a mixed model analysis:
1. Identify desired fixed-effects structure
2. Identify random-effects grouping factors
3. Identify which factors/terms vary within levels of each random-effects grouping factor: maximal model
5. Choose method for calculating *p*-values and fit maximal model

If the maximal model shows critical convergence warnings, reduce random-effects structure:
- Start by removing the correlation among random-effects parameters
- Remove random-effects parameters for highest-order effects with lowest variance
- It can sometimes help to try different optimizers
- Compare *p*-values and fixed-effects estimates across models

---
class: small

### Suppressing Correlations Among Random Effects



.pull-left[

- `lmer` allows suppressing correlation among random effects using `||` syntax. However, **only for numerical variables.**
- `afex::mixed()` allows using `||` also for factors if `expand_re = TRUE`:


```r
m_red &lt;- mixed(dv ~ c_given_a*rel_cond + 
                 (c_given_a*rel_cond||p_id), 
               datr, method = "S", 
               expand_re = TRUE)
```

```r
summary(m_red)$varcor
```

```
##  Groups   Name                       Std.Dev.
##  p_id     (Intercept)                0.1102  
##  p_id.1   re1.c_given_a              0.1757  
##  p_id.2   re1.rel_cond1              0.0842  
##  p_id.3   re1.c_given_a_by_rel_cond1 0.1939  
##  Residual                            0.1723
```
]

.pull-right[

```r
m_red
```

```
## Mixed Model Anova Table (Type 3 tests, S-method)
## 
## Model: dv ~ c_given_a * rel_cond + (c_given_a * rel_cond || p_id)
## Data: datr
##               Effect       df          F p.value
## 1          c_given_a 1, 89.04 484.41 ***  &lt;.0001
## 2           rel_cond 1, 89.44 174.44 ***  &lt;.0001
## 3 c_given_a:rel_cond 1, 85.45  42.24 ***  &lt;.0001
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1
```

![](mixed_models_files/figure-html/unnamed-chunk-22-1.png)&lt;!-- --&gt;
]

---

class: center, middle, inverse

# Exercise 2

---
class: small

### Mixed Models in R: Fitting




```r
require(afex)
m_full &lt;- mixed(dv ~ c_given_a*rel_cond*dv_question +
                       (rel_cond*c_given_a|p_id) +
                       (rel_cond*c_given_a*dv_question|i_id),
                     dat,
                     control = lmerControl(optCtrl = list(maxfun=1e8)),
                     method = "S")
m_full
```


```
## Mixed Model Anova Table (Type 3 tests, S-method)
## 
## Model: dv ~ c_given_a * rel_cond * dv_question + (rel_cond * c_given_a | 
## Model:     p_id) + (rel_cond * c_given_a * dv_question | i_id)
## Data: dat
##                           Effect       df          F p.value
## 1                      c_given_a 1, 33.46 619.36 ***  &lt;.0001
## 2                       rel_cond 2, 16.33  95.07 ***  &lt;.0001
## 3                    dv_question 1, 40.04       0.06     .80
## 4             c_given_a:rel_cond 2, 21.74  22.90 ***  &lt;.0001
## 5          c_given_a:dv_question 1, 24.50       0.01     .94
## 6           rel_cond:dv_question 2, 20.29       0.84     .45
## 7 c_given_a:rel_cond:dv_question 2, 24.15       1.01     .38
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1
```

---
class: small

### Mixed Models in R: Follow-up Analyses


```r
lsm.options(lmer.df = "asymptotic") # or "Kenward-Roger" or "Satterthwaite"
lstrends(m_full, "rel_cond", var = "c_given_a")
```

```
## NOTE: Results may be misleading due to involvement in interactions
```

```
##  rel_cond c_given_a.trend      SE df asymp.LCL asymp.UCL
##  PO                0.7815 0.03525 NA    0.7124    0.8506
##  NE                0.6135 0.04722 NA    0.5210    0.7061
##  IR                0.4339 0.04127 NA    0.3531    0.5148
## 
## Results are averaged over the levels of: dv_question 
## Degrees-of-freedom method: asymptotic 
## Confidence level used: 0.95
```


```r
# fixef(m_full$full_model)[2] + fixef(m_full$full_model)[6]
# fixef(m_full$full_model)[2] + fixef(m_full$full_model)[7]
fixef(m_full$full_model)[2] - fixef(m_full$full_model)[6] - fixef(m_full$full_model)[7]
```

```
## c_given_a 
##    0.4339
```

More examples of interplay between `mixed` or `lmer` with `lsmeans`:
- https://cran.r-project.org/package=afex/vignettes/afex_mixed_example.html
- https://cran.r-project.org/package=lsmeans/vignettes/using-lsmeans.pdf

---
class: small



.pull-left[
### Intraclass Correlation Coefficient (ICC)

Assumption of mixed models: Data points from same unit of observation more similar to each other than unrelated data point.

**Intraclass correlation coefficient (ICC)**: Measure of similarity for data points of a given unit of observations ranging from 0 to 1:
`$$\rho=\frac{\sigma^2_S}{\sigma^2_S+\sigma^2_\epsilon}$$`

&gt; The intraclass correlation `\(\rho\)` can also be interpreted as the expected correlation between two randomly drawn units that are in the same group. (Hox, 2010, p. 15)
]

.pull-right[

```r
m1 &lt;- lmer(dv ~ 1 + (1|p_id), datr)
# summary(m1)
# Random effects:
#  Groups   Name        Variance Std.Dev.
#  p_id     (Intercept) 0.00572  0.0757  
#  Residual             0.14607  0.3822  
# Number of obs: 752, groups:  p_id, 94

0.00572 / (0.0057+0.1461)
```

```
## [1] 0.03768
```

```r
require(sjstats)
icc(m1)
```

```
## Linear mixed model
##  Family: gaussian (identity)
## Formula: dv ~ 1 + (1 | p_id)
## 
##   ICC (p_id): 0.037706
```
]
---
class: small

### Intraclass Correlation Coefficient (ICC)

.pull-left[

```r
m1 &lt;- lmer(dv ~ 1 + (1|p_id), datr)
# summary(m1)
# Random effects:
#  Groups   Name        Variance Std.Dev.
#  p_id     (Intercept) 0.00572  0.0757  
#  Residual             0.14607  0.3822  
# Number of obs: 752, groups:  p_id, 94

icc(m1)
```

```
## Linear mixed model
##  Family: gaussian (identity)
## Formula: dv ~ 1 + (1 | p_id)
## 
##   ICC (p_id): 0.037706
```
]

.pull-right[

```r
m2 &lt;- lmer(dv ~ 1 + (rel_cond:c_given_a|p_id), 
           datr)
# summary(m2)
 # Groups   Name                 Variance Std.Dev. Corr       
 # p_id     (Intercept)          0.0398   0.200               
 #          rel_condPO:c_given_a 1.0186   1.009    -0.94      
 #          rel_condIR:c_given_a 0.3262   0.571    -0.48  0.75
 # Residual                      0.0570   0.239 
icc(m2)
```

```
## Linear mixed model
##  Family: gaussian (identity)
## Formula: dv ~ 1 + (rel_cond:c_given_a | p_id)
## 
##   ICC (p_id): 0.411454
```
]

- ICC useful to determine if mixed models necessary or to determine how multilevel-clustering effects response.
- ICC often not very useful for random-slope models (Goldstein et al., 2002), direct inspection of SDs often more helpful. 

---

# Summary 

- Mixed models allow to directly account for dependencies originating in clustered data via random effects.
- Fixed effects represent the overall/average effect; random effects add offset to specific fixed effects.
- Random-effects parameters are variances of offsets and covariances among different random-effects parameters.
- Random-effects assumed to follow normal distribution thereby implementing partial-pooling / hierarchical-shrinkage (regularization).
- Mixed-models analyses should start with maximal model which includes random slopes for all effects that vary within a random-effects grouping factor.
- If maximal model fails to converge or is singular/degenerate: Start by removing correlation, then highest-order effects.

- Linear mixed models (LMMs) can be extended to generalized linear mixed models (GLMMs) that support different link function and residual distribution (via `glmer` or `mixed`).
- Bayesian estimation possible: `rstanarm::stan_lmer`, `blme`, or `MCMCglmm`.
- More powerful model class: generalized additive mixed models (GAMM; Baayen, Vasisth, Kliegl, &amp; Bates, 2017).

---

class: small
### References Mixed Modeling:
- Singmann, H., &amp; Kellen, D. (in press). An Introduction to Mixed Models for Experimental Psychology. In D. H. Spieler &amp; E. Schumacher (Eds.), *New Methods in Neuroscience and Cognitive Psychology*. Psychology Press. http://singmann.org/download/publications/singmann_kellen-introduction-mixed-models.pdf
- Baayen, H., Vasishth, S., Kliegl, R., &amp; Bates, D. (2017). The cave of shadows: Addressing the human factor with generalized additive mixed models. *Journal of Memory and Language*, 94, 206-234. https://doi.org/10.1016/j.jml.2016.11.006
- Barr, D. J., Levy, R., Scheepers, C., &amp; Tily, H. J. (2013). Random effects structure for confirmatory hypothesis testing: Keep it maximal. *Journal of Memory and Language*, 68(3), 255-278. https://doi.org/10.1016/j.jml.2012.11.001
- Bates, D., Kliegl, R., Vasishth, S., &amp; Baayen, H. (2015). *Parsimonious Mixed Models.* arXiv:1506.04967 [stat]. http://arxiv.org/abs/1506.04967
- Goldstein, H., Browne, W., &amp; Rasbash, J. (2002). Partitioning Variation in Multilevel Models. *Understanding Statistics*, 1(4), 223-231. https://doi.org/10.1207/S15328031US0104_02
- Hox, J. J. (2010). *Multilevel analysis: techniques and applications.* New York: Routledge.
- Matuschek, H., Kliegl, R., Vasishth, S., Baayen, H., &amp; Bates, D. (2017). Balancing Type I error and power in linear mixed models. *Journal of Memory and Language*, 94, 305-315. https://doi.org/10.1016/j.jml.2017.01.001
- https://tjmahr.github.io/plotting-partial-pooling-in-mixed-effects-models/



### References Example Data:
- Skovgaard-Olsen, N., Singmann, H., &amp; Klauer, K. C. (2016). The relevance effect and conditionals. *Cognition*, 150, 26-36. https://doi.org/10.1016/j.cognition.2015.12.017

---
class: small

### Residuals

.pull-left[


```r
plot(m_max, 
     resid(.,scaled=TRUE) ~ c_given_a | rel_cond)
```

![](mixed_models_files/figure-html/unnamed-chunk-32-1.png)&lt;!-- --&gt;
]

.pull-right[

```r
lattice::qqmath(m_max)
```

![](mixed_models_files/figure-html/unnamed-chunk-33-1.png)&lt;!-- --&gt;

]


```r
plot(m_max, p_id ~ resid(., scaled=TRUE) )
plot(m_max, resid(., scaled=TRUE) ~ fitted(.) | rel_cond)
?plot.merMod
```

- https://cran.r-project.org/doc/contrib/Faraway-PRA.pdf
- https://htmlpreview.github.io/?https://github.com/bbolker/iiscvisit/blob/master/workshops/mixedlab.html

---

### Interpreting Residuals
- Zuur et al. (2009). *Mixed Effects Models and Extensions in Ecology with R.* Springer. [Chapter 2]
- Farraway (2002). *Practical Regression and Anova using R*. https://cran.r-project.org/doc/contrib/Faraway-PRA.pdf [Chapter 7]
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {window.dispatchEvent(new Event('resize'));});</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
