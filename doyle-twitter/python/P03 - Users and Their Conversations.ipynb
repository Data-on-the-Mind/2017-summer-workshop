{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search overview\n",
    "\n",
    "We'll end up looking at two main kinds of searches:\n",
    "* *GET search/tweets*, which returns tweets matching a search term\n",
    "* *GET statuses/user_timeline*, which returns all of a given user's tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on timeline iteration: https://dev.twitter.com/rest/public/timelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conversations\n",
    "\n",
    "One cool thing about Twitter as a data source is that it has a lot of interactions. You might be thinking: well, sure, but those interactions are mostly just alt-right trolls tossing Pepes at people who immediately block them, or fans shouting at their idols in hopes of attracting a response from [Paramore](https://twitter.com/after1aughter/status/877661990541336576) or [Five Seconds of Summer](https://twitter.com/Michael5SOS/status/878164242284765184).\n",
    "\n",
    "But lurking beneath those well-worn tropes are actual conversations, and let's try to find a few of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The usual initialization stuff\n",
    "\n",
    "import sys, os, re\n",
    "from pprint import pprint                           #Important for reading through JSONs\n",
    "from time import localtime,strftime,sleep,time      #Important for dealing with Twitter rate limits\n",
    "import datetime                       #Important for processing Twitter timestamps\n",
    "import twitter\n",
    "\n",
    "cons_oauth_file = 'c.xxx'\n",
    "if os.path.exists(cons_oauth_file):\n",
    "    constoken, conssecret = twitter.read_token_file(cons_oauth_file)\n",
    "else:\n",
    "    constoken = raw_input(\"What is your app's 'Consumer Key'?\").strip()\n",
    "    conssecret = raw_input(\"What is your app's 'Consumer Secret'?\").strip()\n",
    "    wf = open(cons_oauth_file,'w'); wf.write(constoken+'\\n'+conssecret); wf.close()\n",
    "    \n",
    "app_oauth_file = 'a.xxx'\n",
    "if not os.path.exists(app_oauth_file):\t\t\t\t\t\t\t\t\t#if user not authorized already\n",
    "\ttwitter.oauth_dance(\"your app\",constoken,conssecret,app_oauth_file)\t\t#perform OAuth Dance\n",
    "apptoken, appsecret = twitter.read_token_file(app_oauth_file)\t\t\t\t\t#import user credentials\n",
    "\n",
    "tsearch = twitter.Twitter(auth=twitter.OAuth(apptoken,appsecret,constoken,conssecret))\t#create search command\\\n",
    "\n",
    "def extracttweetURL(j):\n",
    "\treturn 'http://twitter.com/'+j['user']['screen_name']+'/status/'+str(j['id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, how do we reconstruct a conversation?\n",
    "\n",
    "Lots of tweets are in reply to someone else. (A lot of the \"women/men can be\" tweets from the previous part were, for example.) Twitter uses a linked-list style in its conversation structure, which allows us to crawl back up a conversation.  Let's see how this works in practice.\n",
    "\n",
    "I'm going to cheat and use the first hit from the first time I ran the \"women can be\" search. Here's the tweet, from the wonderfully-named *@bitchardnixon*, on Twitter: http://twitter.com/bitchardnixon/status/878355576719372288\n",
    "\n",
    "It's a really simple back-and-forth conversation between two people who clearly have a history of interactions, exactly the sort of conversation that's been underrepresented in corpus and lab studies.  This is such a stupid, simple interaction, or par with all the other stupid, simple interactions we have every day, but boy, I've never been so excited to see this sort of thing!\n",
    "\n",
    "So how do we collect this data from the API? Well, it's got a [*GET statuses/lookup*](https://dev.twitter.com/rest/reference/get/statuses/lookup) call that returns data on up to 100 tweets at a time.  So let's find out about tweet 878355576719372288!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = tsearch.statuses.lookup(_id=878355576719372288)\n",
    "pprint(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's our data, and there's a feature *in_reply_to_status_id*, which indicates what tweet this one is replying to. There's also *in_reply_to_screen_name* and *in_reply_to_user_id*, which will be useful later on for improving our conversational coverage, but for now let's focus on the specific preceding tweet.  Since we have its ID, we can look it up in the same way.\n",
    "\n",
    "(Two notes: one, since *GET statuses/lookup* can take up to 100 IDs, it returns a list of JSONs (just like *GET search/tweets*), even if only one hit comes back; two, for all the Python *twitter* search functions, to specify and ID as an argument, you have to specify it as *_id=*, with the initial underscore.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.extend(tsearch.statuses.lookup(_id=tweets[0]['in_reply_to_status_id']))\n",
    "pprint(tweets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll repeat with the preceding message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.extend(tsearch.statuses.lookup(_id=tweets[1]['in_reply_to_status_id']))\n",
    "pprint(tweets[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, the *in_reply_to_status_id* field has the value **None**, so we've reached the top of the conversation. What a long, strange trip it's been."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we get down?\n",
    "\n",
    "It's easy to climb up a conversation, in general.  There is the potential for missing branches in the conversational tree; some people regularly delete old tweets, others delete tweets that have gained undue attention, and osme have protected accounts so that randos like you or me can't read them.  If a tweet is deleted or inaccesible, the tweet JSON will still list it as a reply, but you're not going to be able to reconstruct the conversation back to its root. \n",
    "\n",
    "There's also the potential for people to reply out of order; say you've got a 150-character thought to express, so you split it over tweet A and tweet B, and make tweet B a reply to tweet A (yes, you can reply to your own tweets). Now I want to respond, and if I reply to tweet B, you have a nice chain: A-B-me. But if I reply to tweet A -- and people often do respond to the first tweet in a thread -- the context is kind of screwed up.  I don't have any particular advice on this; just something to be aware of.\n",
    "\n",
    "What's really hard is trying to go down a conversation.  Unfortunately, there is no way of seeing the list of tweets that reply to a tweet.  To be honest, I don't even know how exactly Twitter does it when they show all the responses in the web/app views.\n",
    "\n",
    "But here are some approaches that can help with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab a user's timeline\n",
    "\n",
    "This is the *GET statuses/user_timeline* call I mentioned way at the beginning.  If two people are having a long conversation, and we grab all of one person's tweets, we can be reasonably sure of getting almost all of the conversation.  (The only thing we'll miss is if the other person has the last word.)  If we grab the timelines of everyone in the conversation, we ought to get it all.\n",
    "\n",
    "Unlike *GET search/tweets*, which only goes back one week, *GET statuses/user_timeline* will go back up to 3200 tweets, with no time limit.  For non-prolific tweeters, this means you can end up capturing tweets from back in the 2000s! Like, for instance, this guy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note this is a little different from the GET search/tweets call; max_id doesn't work well with a really large minimum.\n",
    "\n",
    "usertweets = []\n",
    "username = 'mgrammar'\n",
    "res = tsearch.statuses.user_timeline(screen_name=username,count=200)\n",
    "minid = 999999999999999999999\n",
    "for i in range(0,16):\n",
    "    print 'Up to tweet', minid, 'iteration', i\n",
    "    if len(res)==0:\n",
    "        break\n",
    "    usertweets.extend(res)\n",
    "    for j in range(0,len(res)):\n",
    "        #print res['statuses'][j]['id']\n",
    "        if res[j]['id'] < minid:\n",
    "            minid = res[j]['id']-1\n",
    "    print 'Hits:', len(res)\n",
    "    #minid = re.search('max_id=([^&]+)&',res['search_metadata']['next_results']).group(1)\n",
    "    print 'New minimum ID:', minid\n",
    "    res = tsearch.statuses.user_timeline(screen_name=username,count=200,max_id=minid)\n",
    "usertweets.extend(res)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GET statuses/user_timeline arguments\n",
    "\n",
    "There are a few important arguments you can send with a call to *GET statuses/user_timeline*:\n",
    "* *user_id/screen_name*: take your pick, either include someone's twitter ID or their screenname for the search. Remember user ID is more stable; you can change your screenname, but not your ID.\n",
    "* *count*: up to a maximum of 200 tweets per search (and up to 3200 total)\n",
    "* *max_id*: the usual; returns the N most recent tweets before *max_id*\n",
    "\n",
    "Two arguments merit a little more discussion:\n",
    "\n",
    "*trim_user*: you know all the stuff in the 'user' dictionary, attached to each tweet?  That's redundant; it's the same for each tweet. If trim_user=True, only the user's ID is returned, and you can look up their information using *GET users/show*. In general, it's good to omit this and just call for user info once. For ease of coding right now, I'll accept redundancy.\n",
    "\n",
    "*include_rts*: Do you want to include tweets the user has retweeted? I usually don't. The default is to include them, and searching with this set to *False* excludes them. I do this for a couple of reasons.\n",
    "\n",
    "1) Retweets aren't that user's words, and people often retweet out of spite, irony, or to point out something they disagree with.  It's very difficult to understand the relationship between a user's feeling and their RT's feelings. \n",
    "\n",
    "2) Including RTs can lead to the same tweet appearing over and over again, especially if you're grabbing multiple people's timelines. \n",
    "\n",
    "3) Twitter doesn't have a standardized flag for RTs. There are signals that something is a retweet, such as the presence of the *'quoted_status'* feature in the tweet information.  You can also search for 'RT @' in the tweet text.  unfortunately, these signals change regularly when Twitter changes its retweet behavior, and different forms of retweets (quote tweeting, manual RTs, and standard RTs) have different signals.  This can really get frustrating.\n",
    "\n",
    "Unfortunately, even setting include_rts to *False* doesn't block all RTs, in my experience.  Be aware of this if your data depends on non-RTs, and I'm happy to give some advice that's worked for me in the past about recognizing and excluding RTs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The \"seed and snowball\" approach\n",
    "\n",
    "A lot of Twitter analyses use a \"user snowball\" approach, which is pretty straightforward. You start out a seed user, or a set of seed users.  You can choose your seed users in a range of ways. One common way is to just select the most recent tweeters, if you're trying to get a broad sample.  You can also pick specific users; I had a project where we we were interested in the interactions between famous (\"verified\") and normal Twitter users, so we chose a few politicians, singers, and scientists who tweeted regularly and actually replied to (at least some of) their fans.  And the basic idea here is that you grab all of the seed user's tweets that you can find, and look at who they mention in their tweets.\n",
    "\n",
    "The snowball part comes from taking all the users the seed user mentions, and treating them as seeds for a second generation. You collect all the mentioned-users' tweets, list everyone they mention, and collect all their tweets.  Though it depends on what your goal is, how many distinct seed users you have, and how much they engage with others, you probably only need one to three generations to build your corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple test case, and maybe one that shows the strengths and shortcomings of this approach. For our seed user, let's use [Michael Clifford](http://twitter.com/micahel5sos) of the band Five Seconds of Summer, a boy band with a pretty solid Twitter following (though I don't believe they're at the level of One Direction or Justin Bieber had).\n",
    "\n",
    "Fandoms are nice for investigating conversations because they're usually friendly, upbeat, and talkative. Definitely much more pleasant than the conversations about politics I was originally using as an example here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, get our seeduser's timeline.\n",
    "username = 'michael5sos'\n",
    "res = tsearch.statuses.user_timeline(screen_name=username,count=200,include_rts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, extract all mentions\n",
    "mentionsdict = {}\n",
    "for t in res:\n",
    "    if len(t['entities']['user_mentions'])>0:\n",
    "        for mention in t['entities']['user_mentions']:\n",
    "            mentionsdict[mention['screen_name']] = mentionsdict.get(mention['screen_name'],0)+1\n",
    "        print extracttweetURL(t)\n",
    "        print t['text']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentionsdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now grab *their* timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Last thing, build an efficient searcher to reconstruct conversations.\n",
    "#(This is definitely outside the scope of today's discussion.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But does this cover everything for reconstructing Twitter conversations?\n",
    "\n",
    "No! Well, maybe, depending on what you're trying to do. But there are a couple small things left to deal with.\n",
    "\n",
    "**Recognizing gaps.** You're gonna have gaps, conversations that can't be traced back to their first tweets.  Depending on your application, this may not matter or may be critical.\n",
    "\n",
    "**Request limit effects.** Because different people tweet different amounts, you might be able to get all the tweets from one side of a conversation, but not the other.  This is especially true whne you're looking back a year or more. You may have to throw out some old conversations because they are just too difficult to fill in.\n",
    "\n",
    "**You can never be sure a conversation ended.** It might turn out that there was a response right after you searched.  Or some random person might have responded, whose timeline you didn't capture. In general, this is not super common and not worrisome, but be very careful using this data to test a hypothesis that rests on identifying the last message in a conversation with high accuracy.\n",
    "\n",
    "#### Two more ways of filling in gaps\n",
    "\n",
    "**Capturing mentions.** You can search for a Tweeter's screen name just like any other search term using *GET search/tweets*, and get the last 3000 mentions of them. The snowball approach only captures people who the seed users mentioned, and with popular accounts, they're only going to mention a small number of those who mention them.\n",
    "\n",
    "**Manual tweet retrieval.** You can also try using *GET statuses/lookup* to grab tweets whose IDs appear in a conversation thread but that haven't been found through timelines/mentions. *GET statuses/lookup* has no time or tweet-number limits, so you can go all the way back to the very earliest tweets in this way."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
